<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: heroku | José Galisteo Ruiz]]></title>
  <link href="http://ceritium.github.io/blog/categories/heroku/atom.xml" rel="self"/>
  <link href="http://ceritium.github.io/"/>
  <updated>2016-08-06T12:44:41+02:00</updated>
  <id>http://ceritium.github.io/</id>
  <author>
    <name><![CDATA[Jose Galisteo Ruiz]]></name>
    <email><![CDATA[ceritium@gmail.com]]></email>
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Heroku y Memcached local]]></title>
    <link href="http://ceritium.github.io/blog/2016/07/07/heroku-y-memcached-local/"/>
    <updated>2016-07-07T15:41:59+02:00</updated>
    <id>http://ceritium.github.io/blog/2016/07/07/heroku-y-memcached-local</id>
    <content type="html"><![CDATA[<p>La única opción &ldquo;oficial&rdquo; para usar memcaché en Heroku es usar el addon
Memcachier o algún otro servicio externo, lo cual está genial pero a veces no es
lo mejor, todo dependerá de nuestra aplicación y la estrategia de <em>caching</em> que
usemos.</p>

<p>En mi caso quiero usar memcached para <em>cachear</em> partes de vistas basándome en el
<code>updated_at</code> de los objetos, una estrategia super sencilla. Además en los listados
puedo hacer desde 10 hasta cientos de peticiones a <em>Memcached</em> pues son caches de
fragmentos anidados.</p>

<p>El problema aquí está en la latencia, por poca que sea, multiplica eso por 100 o
500 peticiones. Lo ideal para mi caso sería tener <em>Memcached</em> corriendo en la
misma maquina que mi aplicación.</p>

<h2>Como ejecutar Memcached local en Heroku dynos</h2>

<p>Añade <code>https://github.com/Americastestkitchen/heroku-buildpack-apt</code> a tu app.
Puedes hacerlo desde consola o la interfaz de <em>Heroku</em>.</p>

<pre><code>$ heroku buildpacks:add https://github.com/Americastestkitchen/heroku-buildpack-apt
</code></pre>

<p>Crea un fichero <code>Aptfile</code> con los paquetes a instalar, en este caso solo
Memcached.</p>

<pre><code># Aptfile

memcached
</code></pre>

<p>Cambia tu <code>Procfile</code> para que ejecute <code>memcached</code> y tu aplicación, en mi caso hice:</p>

<pre><code># Procfile
web: memcached -m 64 &amp; bundle exec puma -C config/puma.rb

# -m es la cantidad de ram
</code></pre>

<p>Con esto cuando vuelvas a desplegar tendrás disponible <code>memcached</code> en cada
<em>dyno</em> dedicado a web. Los parametros son los que vienen por defecto <code>127.0.0.1:11211</code>.</p>

<h2>Cosas a tener en cuenta:</h2>

<p><strong>La cantitdad de RAM disponible</strong></p>

<p>Puedes usar
<a href="https://devcenter.heroku.com/articles/log-runtime-metrics"><code>log-runtime-metrics</code></a> para
monitorizarlo o las estadisticas que ofrece Heroku en el dashboard, pero estas
solo están disponibles para aplicaciones que usan dynos a partir de
<code>standar-1x</code>. Necesitas saber cuánta <em>RAM</em> consume tu app normalmente, cosa que
puedes ver con NewRelic (gratis) y decidir que cantidad le dedicas a Memcached.</p>

<p><strong>Una instancia de Memcached por dyno</strong></p>

<p>Esto es lo que buscábamos al fin y al cabo, si quieres memcached para tus
workers tendrás que hacer lo mismo que para web. Si tienes varios dynos
corriendo cada uno tendrá su propia caché, por lo que tu aplicación debe estar
preparada para ello. Si necesitas una sola instancía de Memcached entonces lo
mejor es que uses un servicio externo.</p>

<p><strong>Volatilidad</strong></p>

<p>Cada vez que <em>despliegues</em> y posiblemente cada vez que hagas un <em>restart</em> perderás
toda la caché. Por esta razón no es buena idea hacer lo mismo para Redis, a
menos que uses Redis única y exclusivamente para caché.</p>

<h2>Las pruebas</h2>

<p>Por último una muestra de mis logs antes y después.</p>

<p><img src="/images/memcached3.png" title="Antes y después" ></p>
]]></content>
  </entry>
  
</feed>
